{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMg6Gpy0LC8yRljdbvUsMeW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulinlina/MedMnist/blob/OrganAMNIST/Convnext_organA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nX4TxOIcflq",
        "outputId": "72c289d6-5513-460a-a9f2-dd2f009357af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ConvNeXt-paddle'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 114 (delta 47), reused 89 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (114/114), 538.16 KiB | 5.38 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/flytocc/ConvNeXt-paddle.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ConvNeXt-paddle\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LXHyXpEcdE2s",
        "outputId": "8f1c1e59-e9b0-4785-9e01-37bc07f66644"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt-paddle\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.22.4)\n",
            "Collecting paddlepaddle_gpu>=2.2 (from -r requirements.txt (line 2))\n",
            "  Downloading paddlepaddle_gpu-2.4.2-cp310-cp310-manylinux1_x86_64.whl (584.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.9/584.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.0.1 (from -r requirements.txt (line 3))\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 4))\n",
            "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.7.0.72)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (2.27.1)\n",
            "Collecting protobuf<=3.20.0,>=3.1.0 (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2))\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (4.4.2)\n",
            "Collecting astor (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2))\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting paddle-bfloat==0.1.7 (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2))\n",
            "  Downloading paddle_bfloat-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (6.0)\n",
            "Collecting pathtools (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle_gpu>=2.2->-r requirements.txt (line 2)) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=ee244da76bab195edf7415ecd88405289f45b5ba250830b0044cdb91a10dab9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, paddle-bfloat, smmap, setproctitle, sentry-sdk, protobuf, Pillow, docker-pycreds, astor, paddlepaddle_gpu, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 Pillow-9.5.0 astor-0.8.1 docker-pycreds-0.4.0 gitdb-4.0.10 paddle-bfloat-0.1.7 paddlepaddle_gpu-2.4.2 pathtools-0.1.2 protobuf-3.20.0 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 加载oraganmnist_axial.npz文件\n",
        "data = np.load('/content/data/organmnist_axial.npz')\n",
        "x_train = data['train_images']\n",
        "y_train = data['train_labels']\n",
        "x_test = data['test_images']\n",
        "y_test = data['test_labels']\n",
        "\n",
        "# 创建输出文件夹\n",
        "output_dir = 'organmnist_axial'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "# 创建训练集和测试集子文件夹\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'val')\n",
        "if not os.path.exists(train_dir):\n",
        "    os.mkdir(train_dir)\n",
        "if not os.path.exists(test_dir):\n",
        "    os.mkdir(test_dir)\n",
        "\n",
        "# 创建每个类别的子文件夹\n",
        "classes = [1, 2,3,4,5,6,7,8,9,10,11] # 每个数字对应一个类别\n",
        "for c in classes:\n",
        "    train_class_dir = os.path.join(train_dir, 'class'+str(c)) # 将数字转换为字符串\n",
        "    test_class_dir = os.path.join(test_dir, 'class'+str(c)) # 将数字转换为字符串\n",
        "    if not os.path.exists(train_class_dir):\n",
        "        os.mkdir(train_class_dir)\n",
        "    if not os.path.exists(test_class_dir):\n",
        "        os.mkdir(test_class_dir)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NF1XjrigdmzX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root ='/content/'\n",
        "# 将图像保存到对应的类别文件夹中\n",
        "for i in range(len(x_train)):\n",
        "    img = x_train[i]\n",
        "    label =int(y_train[i][0])\n",
        "    class_name = classes[label]\n",
        "    img_name = f'train_{i}.png'\n",
        "    img_path = os.path.join(root,train_dir, 'class'+str(class_name), img_name)\n",
        "    # 保存图像为png格式\n",
        "    img = np.squeeze(img) # 去掉多余的维度\n",
        "    img = (img * 255).astype(np.uint8) # 转换为0-255范围的整数\n",
        "    from PIL import Image # 导入PIL库\n",
        "    Image.fromarray(img).save(img_path) # 保存图像\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    img = x_test[i]\n",
        "    label =int(y_test[i])\n",
        "    class_name = classes[label]\n",
        "    img_name = f'test_{i}.png'\n",
        "    img_path = os.path.join(root,test_dir, 'class'+str(class_name), img_name)\n",
        "    # 保存图像为png格式\n",
        "    img = np.squeeze(img) # 去掉多余的维度\n",
        "    img = (img * 255).astype(np.uint8) # 转换为0-255范围的整数\n",
        "    from PIL import Image # 导入PIL库\n",
        "    Image.fromarray(img).save(img_path) # 保存图像\n",
        "\n",
        "# # 删除原始npz文件（可选）\n",
        "# os.remove('tissuemnist.npz')"
      ],
      "metadata": {
        "id": "pZCtBXMfd0dt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCatWbg_hmPq",
        "outputId": "0ceec655-1d0f-478d-cc6c-086ecf021e0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 14 07:14:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ConvNeXt-paddle\n",
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "!python -m paddle.distributed.launch --gpus=\"0\" \\\n",
        "    main.py \\\n",
        "    --model convnext_tiny --drop_path 0.1 \\\n",
        "    --batch_size 64 --lr 4e-3 --accum_iter 8 \\\n",
        "    --warmup_epochs 20 \\\n",
        "    --model_ema --model_ema_eval --dist_eval \\\n",
        "    --data_path /content/organmnist_axial\\\n",
        "    --output_dir output/convnext_tiny \\\n",
        "    --log_wandb \\\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4NbUNN5ehkP",
        "outputId": "4582e8c6-9864-4135-ebf0-d719ecd1c5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt-paddle\n",
            "1\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(parent)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 -----------  Configuration  ----------------------\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:45 - -----------  Configuration  ----------------------\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 devices: 0\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - devices: 0\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 elastic_level: -1\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - elastic_level: -1\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 elastic_timeout: 30\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - elastic_timeout: 30\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 gloo_port: 6767\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - gloo_port: 6767\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 host: None\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - host: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 ips: None\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - ips: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 job_id: default\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - job_id: default\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 legacy: False\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - legacy: False\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 log_dir: log\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - log_dir: log\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 log_level: INFO\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - log_level: INFO\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 master: None\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - master: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 max_restart: 3\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - max_restart: 3\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 nnodes: 1\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - nnodes: 1\n",
            "LAUNCH INFO 2023-06-14 07:24:31,294 nproc_per_node: None\n",
            "[2023-06-14 07:24:31,294] [    INFO] __init__.py:47 - nproc_per_node: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 rank: -1\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - rank: -1\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 run_mode: collective\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - run_mode: collective\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 server_num: None\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - server_num: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 servers: \n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - servers: \n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 start_port: 6070\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - start_port: 6070\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 trainer_num: None\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - trainer_num: None\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 trainers: \n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - trainers: \n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 training_script: main.py\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - training_script: main.py\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 training_script_args: ['--model', 'convnext_tiny', '--drop_path', '0.1', '--batch_size', '64', '--lr', '4e-3', '--accum_iter', '8', '--warmup_epochs', '20', '--model_ema', '--model_ema_eval', '--dist_eval', '--data_path', '/content/organmnist_axial', '--output_dir', 'output/convnext_tiny', '--log_wandb']\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - training_script_args: ['--model', 'convnext_tiny', '--drop_path', '0.1', '--batch_size', '64', '--lr', '4e-3', '--accum_iter', '8', '--warmup_epochs', '20', '--model_ema', '--model_ema_eval', '--dist_eval', '--data_path', '/content/organmnist_axial', '--output_dir', 'output/convnext_tiny', '--log_wandb']\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 with_gloo: 1\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:47 - with_gloo: 1\n",
            "LAUNCH INFO 2023-06-14 07:24:31,295 --------------------------------------------------\n",
            "[2023-06-14 07:24:31,295] [    INFO] __init__.py:48 - --------------------------------------------------\n",
            "LAUNCH INFO 2023-06-14 07:24:31,296 Job: default, mode collective, replicas 1[1:1], elastic False\n",
            "[2023-06-14 07:24:31,296] [    INFO] controller.py:168 - Job: default, mode collective, replicas 1[1:1], elastic False\n",
            "LAUNCH INFO 2023-06-14 07:24:31,297 Run Pod: izlzen, replicas 1, status ready\n",
            "[2023-06-14 07:24:31,297] [    INFO] controller.py:60 - Run Pod: izlzen, replicas 1, status ready\n",
            "LAUNCH INFO 2023-06-14 07:24:31,310 Watching Pod: izlzen, replicas 1, status running\n",
            "[2023-06-14 07:24:31,310] [    INFO] controller.py:80 - Watching Pod: izlzen, replicas 1, status running\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(parent)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/paddle/distributed/parallel.py:173: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
            "  warnings.warn(\n",
            "[07:24:33.463368] job dir: /content/ConvNeXt-paddle\n",
            "[07:24:33.463509] Namespace(batch_size=64,\n",
            "epochs=300,\n",
            "accum_iter=8,\n",
            "model='convnext_tiny',\n",
            "input_size=224,\n",
            "drop_path=0.1,\n",
            "layer_scale_init_value=1e-06,\n",
            "model_ema=True,\n",
            "model_ema_decay=0.9999,\n",
            "model_ema_eval=True,\n",
            "opt='adamw',\n",
            "opt_eps=1e-08,\n",
            "opt_betas=None,\n",
            "clip_grad=None,\n",
            "weight_decay=0.05,\n",
            "use_amp=False,\n",
            "blr=0.0005,\n",
            "lr=0.004,\n",
            "warmup_lr=0,\n",
            "min_lr=1e-06,\n",
            "warmup_epochs=20,\n",
            "t_in_epochs=False,\n",
            "color_jitter=0.4,\n",
            "aa='rand-m9-mstd0.5-inc1',\n",
            "smoothing=0.1,\n",
            "train_interpolation='bicubic',\n",
            "reprob=0.25,\n",
            "remode='pixel',\n",
            "recount=1,\n",
            "resplit=False,\n",
            "mixup=0.8,\n",
            "cutmix=1.0,\n",
            "cutmix_minmax=None,\n",
            "mixup_prob=1.0,\n",
            "mixup_switch_prob=0.5,\n",
            "mixup_mode='batch',\n",
            "finetune='',\n",
            "head_init_scale=1.0,\n",
            "data_path='/content/organmnist_axial',\n",
            "nb_classes=1000,\n",
            "cls_label_path_train=None,\n",
            "cls_label_path_val=None,\n",
            "output_dir='output/convnext_tiny',\n",
            "seed=2022,\n",
            "resume='',\n",
            "resume_ema='',\n",
            "start_epoch=0,\n",
            "eval=False,\n",
            "dist_eval=True,\n",
            "num_workers=10,\n",
            "log_wandb=True,\n",
            "wandb_entity=None,\n",
            "wandb_project=None,\n",
            "debug=False)\n",
            "wandb: Currently logged in as: yulinlin. Use `wandb login --relogin` to force relogin\n",
            "wandb: Tracking run with wandb version 0.15.4\n",
            "wandb: Run data is saved locally in /content/ConvNeXt-paddle/wandb/run-20230614_072435-xgvfa1n5\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run resilient-butterfly-29\n",
            "wandb: ⭐️ View project at https://wandb.ai/yulinlin/ConvNeXt-paddle\n",
            "wandb: 🚀 View run at https://wandb.ai/yulinlin/ConvNeXt-paddle/runs/xgvfa1n5\n",
            "[07:24:36.213166] Mixup is activated!\n",
            "W0614 07:24:36.217592  5389 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.7\n",
            "W0614 07:24:36.707585  5389 gpu_resources.cc:91] device: 0, cuDNN Version: 8.7.\n",
            "[07:24:38.046449] actual lr: 4.00e-03\n",
            "[07:24:38.047090] accumulate grad iterations: 8\n",
            "[07:24:38.047547] effective batch size: 512\n",
            "[07:24:38.047925] Number of training examples = 34581\n",
            "[07:24:38.048270] Number of training training per epoch = 67\n",
            "/usr/local/lib/python3.10/dist-packages/paddle/fluid/dygraph/parallel.py:655: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.\n",
            "  warnings.warn(\"The program will return to single-card operation. \"\n",
            "[07:24:38.081373] number of params: 28.589128 M\n",
            "[07:24:38.082033] Start training for 300 epochs\n",
            "[07:24:52.664696] Epoch: [0]  [  0/540]  eta: 2:11:12  lr: 0.000000  loss: 7.0790 (7.0790)  time: 14.5787  data: 3.3967\n",
            "[07:25:09.678044] Epoch: [0]  [ 20/540]  eta: 0:13:02  lr: 0.000006  loss: 7.0112 (7.0131)  time: 0.8505  data: 0.0037\n",
            "[07:25:26.756898] Epoch: [0]  [ 40/540]  eta: 0:09:53  lr: 0.000015  loss: 6.8955 (6.9565)  time: 0.8537  data: 0.0040\n",
            "[07:25:44.035970] Epoch: [0]  [ 60/540]  eta: 0:08:38  lr: 0.000021  loss: 6.6912 (6.8677)  time: 0.8638  data: 0.0038\n",
            "[07:26:01.680796] Epoch: [0]  [ 80/540]  eta: 0:07:54  lr: 0.000030  loss: 6.3548 (6.7361)  time: 0.8821  data: 0.0025\n",
            "[07:26:19.609241] Epoch: [0]  [100/540]  eta: 0:07:22  lr: 0.000036  loss: 5.8912 (6.5642)  time: 0.8962  data: 0.0018\n",
            "[07:26:38.175716] Epoch: [0]  [120/540]  eta: 0:06:56  lr: 0.000045  loss: 5.3455 (6.3582)  time: 0.9281  data: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install paddlepaddle-gpu==2.4.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqugYKffh2Qa",
        "outputId": "ba2483aa-8e84-45fe-e3f4-c6fb78755f63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
            "Collecting paddlepaddle-gpu==2.4.2.post117\n",
            "  Downloading https://paddle-wheel.bj.bcebos.com/2.4.2/linux/linux-gpu-cuda11.7-cudnn8.4.1-mkl-gcc8.2-avx/paddlepaddle_gpu-2.4.2.post117-cp310-cp310-linux_x86_64.whl (557.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.3/557.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (1.22.4)\n",
            "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (3.20.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (9.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (0.8.1)\n",
            "Requirement already satisfied: paddle-bfloat==0.1.7 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.4.2.post117) (3.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.2.post117) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.2.post117) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.2.post117) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==2.4.2.post117) (3.4)\n",
            "Installing collected packages: paddlepaddle-gpu\n",
            "Successfully installed paddlepaddle-gpu-2.4.2.post117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnSSNGECjxqo",
        "outputId": "06759b5d-8406-4175-ecf8-97102f095dd9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1mLet's setup this directory for W&B!\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Which project should we use?\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) ConvNeXt-paddle\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) medmnist\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) convnext\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (4) Create New\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'ConvNeXt-paddle'\n",
            "\u001b[32mThis directory is configured!  Next, track a run:\n",
            "\u001b[0m* In your training script:\n",
            "    \u001b[1mimport wandb\u001b[0m\n",
            "    \u001b[1mwandb.init(project=\"ConvNeXt-paddle\")\u001b[0m\n",
            "* then `\u001b[1mpython <train.py>\u001b[0m`.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}